{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    },
    "colab": {
      "name": "image_projection_colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dvschultz/make-ml-datasets/blob/master/image_projection_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UqHzl-nrU5N",
        "colab_type": "text"
      },
      "source": [
        "# Image Projection with PCA and UMAP\n",
        "\n",
        "Shared by Adam Evans"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcCvN34jYYDo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install efficientnet_pytorch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4c_TadQzYL-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from umap import UMAP\n",
        "\n",
        "from sklearn.decomposition import PCA, NMF\n",
        "\n",
        "from torch import no_grad, flatten\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.offsetbox import OffsetImage, AnnotationBbox"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SknqdSJtcETQ",
        "colab_type": "text"
      },
      "source": [
        "Make a directory at the top level of Colab. This is where we will put our folder of images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNdOpzV6a9fL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvIubNdkZmy4",
        "colab_type": "text"
      },
      "source": [
        "## Get Dataset\n",
        "\n",
        "You have two options (I might recommend the second so you donâ€™t accidentally remove files from Drive):\n",
        "1. Work directly from Google Drive (first cell); or\n",
        "2. Download your images using gdown (second cell)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPp0MPQIYeDo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNYaa_88Zz7i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gdown --id 1nwzWHI8K_x7L9EePKVK3lrjLsqljakmC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nX91EFnzjXru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip /content/annales1024.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSn9Rqg3aqwN",
        "colab_type": "text"
      },
      "source": [
        "Once your images are accessible in Colab, move the folder of your images (the folder, not just the images) into the `images` folder at the top level in Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1E0X1ktYL-p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_to_image_folder = '/content/images/'\n",
        "# note there is a folder within this one with the jpg files\n",
        "batch_size = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AS_0pOcBYL-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://github.com/lukemelas/EfficientNet-PyTorch\n",
        "model = EfficientNet.from_pretrained('efficientnet-b0', )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjY1L8wVYL-u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ImageFolderWithPaths(datasets.ImageFolder):\n",
        "    \"\"\"Custom dataset that includes image file paths\"\"\"\n",
        "\n",
        "    # override the __getitem__ method. this is the method that dataloader calls\n",
        "    def __getitem__(self, index):\n",
        "        # this is what ImageFolder normally returns \n",
        "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
        "        # the image file path\n",
        "        path = self.imgs[index][0]\n",
        "        # make a new tuple that includes original and the path\n",
        "        tuple_with_path = (original_tuple + (path,))\n",
        "        return tuple_with_path\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHMvKqxfYL-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getImage(path, zoom):\n",
        "    return OffsetImage(plt.imread(path), zoom=zoom)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kw8T9f-NYL-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_thumbs(embed, all_processed_image_paths, canvas_size=28, zoom=0.05):\n",
        "    '''Plot thumbnails at projected points in latent space'''\n",
        "    \n",
        "    assert X_features.shape[0] == len(all_processed_image_paths)\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(canvas_size, canvas_size/1.618))\n",
        "    ax.scatter(embed[:,0], embed[:,1]) \n",
        "    \n",
        "    for x0, y0, path in zip(embed[:,0], embed[:,1], all_processed_image_paths):\n",
        "        ab = AnnotationBbox(getImage(path, zoom), (x0, y0), frameon=False)\n",
        "        ax.add_artist(ab)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxqevgJ4YL-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imagenet preprocessing\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "# extension of ImageFolder\n",
        "# from https://gist.github.com/andrewjong/6b02ff237533b3b2c554701fb53d5c4d\n",
        "dataset = ImageFolderWithPaths(path_to_image_folder,\n",
        "    transforms.Compose([\n",
        "        transforms.Resize(224),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        normalize,\n",
        "    ]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7kYxJYVYL-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=1,\n",
        "    pin_memory=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIEBTcedYL-8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_processed_image_paths, all_features, all_images = [], [], []\n",
        "\n",
        "# iterate through batches and transform image into feature vector\n",
        "with no_grad():\n",
        "    for i, (images, target, paths) in enumerate(train_loader):\n",
        "        if i == 0: print('Converting images to features...')\n",
        "        \n",
        "        # run efficientnet over the images\n",
        "        # https://github.com/lukemelas/EfficientNet-PyTorch#example-feature-extraction\n",
        "        features = model.extract_features(images)\n",
        "        \n",
        "        flat_images = flatten(images, start_dim=1).detach().numpy()\n",
        "        flat_features = flatten(features, start_dim=1).detach().numpy()\n",
        "        \n",
        "        all_images.append(flat_images)        \n",
        "        all_features.append(flat_features)\n",
        "        all_processed_image_paths.extend(paths)\n",
        "        print(f'Featurized batch #{i} - {min(((i+1)*batch_size) / len(dataset),1.0)}')\n",
        "\n",
        "X_pixels = np.concatenate(all_images)\n",
        "X_features = np.concatenate(all_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcyB8H_PYL--",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_pixels.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jt1iJ8xKYL_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_features.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJsVpA5gYL_D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reduce raw channels X pixels to 2 dimensions with PCA\n",
        "pca = PCA(n_components=2)\n",
        "embed = pca.fit_transform(X_pixels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ven0lQOGYL_F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lovely dark --> light embedding\n",
        "plot_thumbs(embed, all_processed_image_paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erCCY-FPYL_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reduce raw channels X pixels to 2 dimensions with UMAP\n",
        "umap = UMAP(n_components=2)\n",
        "embed = umap.fit_transform(X_pixels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nNWd-zOYL_K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# more.. compact? dark --> light embedding\n",
        "plot_thumbs(embed, all_processed_image_paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ek0ptWr-YL_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reduce features from efficientnet to 2 dimensions with PCA\n",
        "pca = PCA(n_components=2)\n",
        "embed = pca.fit_transform(X_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4UNpYmVYL_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# seems to pick up a more triangular pattern\n",
        "# direction is much easier to interpret\n",
        "#   --> goes from busy image / bushy to the left and clean / isolated to the right\n",
        "plot_thumbs(embed, all_processed_image_paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWFqVn-9YL_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reduce features from efficientnet to 2 dimensions with UMAP\n",
        "umap_2 = UMAP(n_components=2)\n",
        "embed = umap_2.fit_transform(X_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6XjNnDPYL_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# some kind of embedding.. seems to pick up on same-scene \"duplicates\" nicely\n",
        "plot_thumbs(embed, all_processed_image_paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uv7R6KYtYL_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rm -r /content/images/bonnebone-256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcEiiXsfke8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}